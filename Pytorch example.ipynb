{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch import optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=20, shuffle=True)\n",
    "\n",
    "\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "testimages, testlabels = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 784])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = images.view(images.shape[0], -1)\n",
    "testimages = testimages.view(testimages.shape[0], -1)\n",
    "\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relu-SoftMax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu-Softmax / Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adelgado/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.497971807916959\n",
      "Accuracy: 50.0%\n",
      "Training loss: 1.0415674607753753\n",
      "Accuracy: 44.999998807907104%\n",
      "Training loss: 0.8008145861725012\n",
      "Accuracy: 55.000001192092896%\n",
      "Training loss: 0.6831205493311088\n",
      "Accuracy: 69.9999988079071%\n",
      "Training loss: 0.5153118489931027\n",
      "Accuracy: 89.99999761581421%\n",
      "Accuracy: 85.00000238418579%\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model1 = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.Softmax(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adamax(model1.parameters(), lr=0.003)\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model1(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "        top_p, top_class = output.topk(1, dim=1)\n",
    "\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "        print(f'Accuracy: {accuracy.item()*100}%')        \n",
    "top_p, top_class = model1(testimages).topk(1, dim=1)\n",
    "\n",
    "equals = top_class == testlabels.view(*top_class.shape)\n",
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "print(f'Accuracy: {accuracy.item()*100}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu-Softmax / RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.3024120899041494\n",
      "Accuracy: 10.000000149011612%\n",
      "Training loss: 2.3021423166592916\n",
      "Accuracy: 25.0%\n",
      "Training loss: 2.3021230963071186\n",
      "Accuracy: 20.000000298023224%\n",
      "Training loss: 2.3023310285409293\n",
      "Accuracy: 0.0%\n",
      "Training loss: 2.3021843106746673\n",
      "Accuracy: 30.000001192092896%\n",
      "Accuracy: 15.000000596046448%\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model3 = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.Softmax(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model3.parameters(), lr=0.003)\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model3(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "        top_p, top_class = output.topk(1, dim=1)\n",
    "\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "        print(f'Accuracy: {accuracy.item()*100}%')        \n",
    "        \n",
    "        \n",
    "top_p, top_class = model3(testimages).topk(1, dim=1)\n",
    "\n",
    "equals = top_class == testlabels.view(*top_class.shape)\n",
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "print(f'Accuracy: {accuracy.item()*100}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu-Softmax / SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.302479820330938\n",
      "Accuracy: 20.000000298023224%\n",
      "Training loss: 2.300350705862045\n",
      "Accuracy: 5.000000074505806%\n",
      "Training loss: 2.299140646696091\n",
      "Accuracy: 5.000000074505806%\n",
      "Training loss: 2.296819148461024\n",
      "Accuracy: 20.000000298023224%\n",
      "Training loss: 2.266268878062566\n",
      "Accuracy: 25.0%\n",
      "Accuracy: 25.0%\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model5 = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.Softmax(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model5.parameters(), lr=0.003)\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model5(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "        top_p, top_class = output.topk(1, dim=1)\n",
    "\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "        print(f'Accuracy: {accuracy.item()*100}%')        \n",
    "        \n",
    "        \n",
    "top_p, top_class = model5(testimages).topk(1, dim=1)\n",
    "\n",
    "equals = top_class == testlabels.view(*top_class.shape)\n",
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "print(f'Accuracy: {accuracy.item()*100}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relu-Softmax-Relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu-Soft-Relu / Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7511923342930774\n",
      "Accuracy: 94.9999988079071%\n",
      "Training loss: 0.2120493494841891\n",
      "Accuracy: 94.9999988079071%\n",
      "Training loss: 0.1489307107553662\n",
      "Accuracy: 80.0000011920929%\n",
      "Training loss: 0.12036036172361735\n",
      "Accuracy: 100.0%\n",
      "Training loss: 0.10419753631049146\n",
      "Accuracy: 100.0%\n",
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model8 = nn.Sequential(nn.Linear(784, 256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(256, 128),\n",
    "                      nn.Softmax(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adamax(model8.parameters(), lr=0.003)\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model8(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "        top_p, top_class = output.topk(1, dim=1)\n",
    "\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "        print(f'Accuracy: {accuracy.item()*100}%')\n",
    "        \n",
    "        \n",
    "top_p, top_class = model8(testimages).topk(1, dim=1)\n",
    "\n",
    "equals = top_class == testlabels.view(*top_class.shape)\n",
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "print(f'Accuracy: {accuracy.item()*100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "top_p, top_class = model8(testimages).topk(1, dim=1)\n",
    "\n",
    "equals = top_class == testlabels.view(*top_class.shape)\n",
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "print(f'Accuracy: {accuracy.item()*100}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarda 1'49\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu-Soft-Relu / RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.301841409921646\n",
      "Accuracy: 10.000000149011612%\n",
      "Training loss: 2.301830239375432\n",
      "Accuracy: 30.000001192092896%\n",
      "Training loss: 2.3017399570941923\n",
      "Accuracy: 10.000000149011612%\n",
      "Training loss: 2.301629289865494\n",
      "Accuracy: 10.000000149011612%\n",
      "Training loss: 2.3017541761398315\n",
      "Accuracy: 15.000000596046448%\n",
      "Accuracy: 15.000000596046448%\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model10 = nn.Sequential(nn.Linear(784, 256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(256, 128),\n",
    "                      nn.Softmax(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model10.parameters(), lr=0.003)\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model10(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "        top_p, top_class = output.topk(1, dim=1)\n",
    "\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "        print(f'Accuracy: {accuracy.item()*100}%')        \n",
    "        \n",
    "top_p, top_class = model10(testimages).topk(1, dim=1)\n",
    "\n",
    "equals = top_class == testlabels.view(*top_class.shape)\n",
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "print(f'Accuracy: {accuracy.item()*100}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu-Soft-Relu / SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.303156809091568\n",
      "Accuracy: 20.000000298023224%\n",
      "Training loss: 2.30074604956309\n",
      "Accuracy: 15.000000596046448%\n",
      "Training loss: 2.299807936112086\n",
      "Accuracy: 15.000000596046448%\n",
      "Training loss: 2.298934292236964\n",
      "Accuracy: 0.0%\n",
      "Training loss: 2.297786432981491\n",
      "Accuracy: 5.000000074505806%\n",
      "Accuracy: 15.000000596046448%\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model12 = nn.Sequential(nn.Linear(784, 256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(256, 100),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(100, 32),\n",
    "                      nn.Softmax(),\n",
    "                      nn.Linear(32, 10))\n",
    "\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model12.parameters(), lr=0.003)\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model12(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "        top_p, top_class = output.topk(1, dim=1)\n",
    "\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "        print(f'Accuracy: {accuracy.item()*100}%')        \n",
    "        \n",
    "        \n",
    "top_p, top_class = model12(testimages).topk(1, dim=1)\n",
    "\n",
    "equals = top_class == testlabels.view(*top_class.shape)\n",
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "print(f'Accuracy: {accuracy.item()*100}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "images, labels = next(iter(trainloader))\n",
    "img = images[0].view(1, 784)\n",
    "logps = model8(img)\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
